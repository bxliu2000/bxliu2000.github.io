<!doctype html>
<html lang="en">
<head>
    <meta charset="utf-8">
    <link rel="stylesheet" href="simple.css">
    <title>Project Four</title>
    <meta name="Brian Liu" content="SitePoint">
</head>

<body>
    <h1>Fun with neural networks!</h1>
        <h2>Part 1: Nose Detection</h2>
            <h3>Sample Images from Dataloader</h3>
                <img src="./results/pt_1/pt1_dataloader.png">
            <h3>Training and Validation Accuracy </h3>
                <p>Plotted below are the training and validation accuracy trend lines for a total of 25 epochs. Blue is the training loss & orange is the loss on testing data. </p>
                <img src="./results/pt_1/epoch_loss_decrease.png" height="400" width="500">
            <h3>Examples of successes!</h3>
                <img src="./results/pt_1/prediction_30_25.png" height="300" width="400">
                <img src="./results/pt_1/prediction_11_25.png" height="300" width="400">
                <img src="./results/pt_1/prediction_15_25.png" height="300" width="400">
                <img src="./results/pt_1/prediction_16_25.png" height="300" width="400">
                <img src="./results/pt_1/prediction_34_25.png" height="300" width="400">
                <img src="./results/pt_1/prediction_35_25.png" height="300" width="400">
            <h3>Examples of failures!</h3>
                <img src="./results/pt_1/prediction_23_25.png" height="300" width="400">
                <img src="./results/pt_1/prediction_31_25.png" height="300" width="400">
                <img src="./results/pt_1/prediction_36_25.png" height="300" width="400">
            <h4>Why failure?</h4>
            <p>If we take a closer look at the failure photos, we can see that our prediction is detecting a point where the pattern at that position resembles that of a nose. For example with the woman, the dimples in her smile create a similar pattern to that of a nose, and the last man's eyebags also has a similar pattern to that of a nose as well. Thus I believe that the filter in the first layer which is trained to recognize the pixel composition of a nose is mistaking these other features on the face for that of a nose. </p>
        <h2>Part 2: Detecting the rest of the faces</h2>
            <h3>Sample Images from Dataloader</h3>
                <p>For Data Augmentation, I incorporated random changes in brightness, saturation, randomly cropping my image within a specified window, and randomly rotating it from -15 to 15 degrees. Below are some examples.</p>
                <img src="./results/pt_2/pt_2_dataloader.png">
            <h3>My Neural Architecture</h3>
                <p>For task two I actually forewent the advice and stayed with 4 thicc convolutional layers instead of 5-6. After tons of experimentation, I got far better results with 4 layers and I hypothesizoe it is because my image size is still relatively small. I chose to pass in image sizes of 160x120. </p>
                <p>Convolutional layer1: I had a 20 channel 5x5 convolutional layer followed by a relu and a maxpool.</p>
                <p>Convolutional layer2: Another 20 channel 5x5x20 convolutional layer followed by a relu and a maxpool.</p>
                <p>Convolutional layer3: A 40 channel 5x5x20 convolutional layer followed by a relu and a maxpool</p>
                <p>layer4: a 60 channel 3x3x40 convolutional layer straight into the fully connected layers.</p>
                <p>Fully connected layer 1: a 640x7560 matrix followed by a relu.</p>
                <p>Fully connected layer 2: a 116x640 matrix.</p>
                
                <p>As we can see, instead of limiting my channel size to 12-28, I actually increased it to about 40 for the last two layers and got far better results. When I was experimenting with the 5-layered CNN with 12-28 channel sizes, my predictions tended to be more of an average of the facial poisitions.</p>

            <h3>Training and Validation Accuracy </h3>
                <img src="./results/pt_2/epoch_loss_decrease.png" height="400" width="500">
            <h3>Visualization of weights! </h2>
                <img src="./results/pt_2/19weight_visualization.png">
            <h3>Examples of successes!</h3>
                <img src="./results/pt_2/prediction_1_25.png" height="300" width="400">
                <img src="./results/pt_2/prediction_17_25.png" height="300" width="400">
                <img src="./results/pt_2/prediction_31_25.png" height="300" width="400">
                <img src="./results/pt_2/prediction_38_25.png" height="300" width="400">
                <img src="./results/pt_2/prediction_43_25.png" height="300" width="400">
                <img src="./results/pt_2/prediction_15_25.png" height="300" width="400">
            <h3>Examples of failures!</h3>
                <img src="./results/pt_2/prediction_18_25.png" height="300" width="400">
                <img src="./results/pt_2/prediction_7_25.png" height="300" width="400">
                <img src="./results/pt_2/prediction_24_25.png" height="300" width="400">
            <p>As seen above my model is able to account for faces that are rotated, but not so much faces where they face strongly in a single direction. As seen by the bottom examples, the model has trouble identifying the orientation of the face. </p>
        <h3>Part 3 is coming! I just need to get my photos off of google colab but my internet is shaky.</h3>
</body>
</html>